{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "facial-expression-recognizer.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaisal1311/Deep-Learning/blob/master/Computer%20Vision/facial_expression_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41qXO0nnq4Cs",
        "colab_type": "text"
      },
      "source": [
        "# The Notebook file where I am going to create the model and train it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZjYv3Hmq4Cv",
        "colab_type": "text"
      },
      "source": [
        "The plan is to create a human visual system like replica for computer to look through camera working as their eyes and understand the mood by reading on facial expression.\n",
        "\n",
        "I will load the data here, make it ready or the model, then create the model and train it here. After it is done I will save the trained parameters to use in a python script which can understand the facial expression with the help of camera and the OpenCV module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Alj3aajUq4Cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the imports we may need to use later in the notebook\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch, os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPzbenn7q4C-",
        "colab_type": "text"
      },
      "source": [
        "## 1. Getting the Data and Understanding it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYM83PLmq4DA",
        "colab_type": "text"
      },
      "source": [
        "After looking around the internet I found a dataset in csv format known as FER2013 containing pixel values of the photos and their respective classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "0PkUsPBjq4DD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us first load the dataset\n",
        "df = pd.read_csv('../input/fer2013/fer2013.csv') # This is because I used the notebook to train on kaggle\n",
        "\n",
        "# df = pd.read_csv('/data/fer2013.csv')\n",
        "\n",
        "# and then take a look at the csv dataframe\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoakoAJ-q4DM",
        "colab_type": "text"
      },
      "source": [
        "After taking a look at the data frame we can see clearly that there are 3 columns in the \n",
        "frame first has the index number of the classes that is 0 for happy face and 1 for sad but we do not know which is what yet so we will categorize it ourselves a little later\n",
        "\n",
        "The second column contains the pixel values for the photo of the faces with the respective reactions and usage column states which data rows are for testing which are for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPRug7CNq4DO",
        "colab_type": "text"
      },
      "source": [
        "Let us try to take out someinsights from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NZE-4td2q4DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Total lenth of dataset: ', len(df.Usage), '\\n') # Which is actually also the lenth of total dataframe\n",
        "print('Total Categories we have: ', df.Usage.unique())\n",
        "print('Number of data in each category: ', '{ Training: ', len(df[df.Usage == 'Training']), ' PublicTest: ', len(df[df.Usage == 'PublicTest']), ' PrivateTest: ', len(df[df.Usage == 'PrivateTest']), '}\\n')\n",
        "print('Total Expression Classes we have: ', df.emotion.unique(), '\\n')\n",
        "print('Type of the pixel data is: ', type(df.pixels[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3RQLMh9q4Dh",
        "colab_type": "text"
      },
      "source": [
        "Now let us try to understand which clas of the expression represents which expression ourselves!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "rkhrFnhXq4Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# since the pixels are in a single long presentation this function will turn it to a matrix of 48x48\n",
        "def makemtrx(lst, n=48):\n",
        "    for i in range(0, 48*48, n):  \n",
        "        yield lst[i:i + n] \n",
        "\n",
        "# This function will help to show the images\n",
        "def showimg(data):\n",
        "    pixel = [int(i) for i in data[1].split(' ')]\n",
        "    pixel = np.array(list(makemtrx(pixel)))\n",
        "    plt.imshow(pixel, cmap='gray')\n",
        "    plt.xlabel(f'Expression Class: {data[0]}')\n",
        "    plt.plot()\n",
        "\n",
        "for i in range(7):\n",
        "    plt.figure()\n",
        "    showimg(df[df.emotion == i].values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YWzpo9nq4Dp",
        "colab_type": "text"
      },
      "source": [
        "After looking at the expressionin the photos i can conclude the classes for the expression below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YjH1HuGiq4Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = {\n",
        "    0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1lD3AMlq4Du",
        "colab_type": "text"
      },
      "source": [
        "Now let me get the data ready for the model!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HVXFE5YJq4Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the dataset ready\n",
        "df_train = pd.concat([df[(df.Usage == 'Training')], df[df.Usage == 'PublicTest']], ignore_index=True).drop(['Usage'], axis=1)\n",
        "df_test = df[df.Usage == 'PrivateTest'].drop(['Usage'], axis=1).reset_index().drop(['index'], 1)\n",
        "\n",
        "# differentiating between labels and images\n",
        "train_images = df_train.iloc[:, 1]\n",
        "train_labels = df_train.iloc[:, 0]\n",
        "test_images = df_test.iloc[:, 1]\n",
        "test_labels = df_test.iloc[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrJdH-iFq4Dz",
        "colab_type": "text"
      },
      "source": [
        "Now we will create a class for the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iPmuZzlIq4D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is for the transforms\n",
        "train_trfm = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.RandomCrop(48, padding=4, padding_mode='reflect'),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5), (0.5), inplace=True)\n",
        "    ])\n",
        "val_trfm = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5), (0.5))\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XcTsx0dRq4D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the class for our dataset for the FER\n",
        "class FERDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, images, labels, transforms):\n",
        "        self.X = images\n",
        "        self.y = labels\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        data = [int(m) for m in self.X[i].split(' ')]\n",
        "        data = np.asarray(data).astype(np.uint8).reshape(48,48,1)\n",
        "        data = self.transforms(data)\n",
        "        label = self.y[i]\n",
        "        return (data, label)\n",
        "    \n",
        "# assigning the transformed data\n",
        "train_data = FERDataset(train_images, train_labels, train_trfm)\n",
        "val_data = FERDataset(test_images, test_labels, val_trfm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBnAV-Ijq4D6",
        "colab_type": "text"
      },
      "source": [
        "I'll be using the test data as validation data since the test data is also labeled,that way I get more data.\n",
        "Getting the data ready is done, now lets just inspect if everything is all right or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XASQ4k1Aq4D7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showimg(data):\n",
        "    img, lbl = data\n",
        "    plt.figure()\n",
        "    plt.imshow(torch.squeeze(img), cmap='gray')\n",
        "    plt.xlabel(f'{classes[lbl]} ({lbl})')\n",
        "    plt.plot()\n",
        "    \n",
        "showimg(train_data[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06b_fFV9q4D-",
        "colab_type": "text"
      },
      "source": [
        "Now when the data is ready we will have a validation dataset and dataloader for them with batch sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bRDLXY3oq4EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bKg_cKPNq4EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_num = 400\n",
        "\n",
        "train_dl = DataLoader(train_data, batch_num, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_dl = DataLoader(val_data, batch_num*2, num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsTQZ9uGq4EI",
        "colab_type": "text"
      },
      "source": [
        "Since the dataloader and eevrything is ready now, lets take a look at the photos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2gQrZLruq4EJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "        break\n",
        "        \n",
        "show_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aTzprbXq4EM",
        "colab_type": "text"
      },
      "source": [
        "Everything is completed with the data processing! Now we can begin creating our model!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EeLoYxcq4EM",
        "colab_type": "text"
      },
      "source": [
        "## Creating The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljOGqrO6q4EO",
        "colab_type": "text"
      },
      "source": [
        "We will craete a base class for the image classification about the expression which will later be encapsuled in the class for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fhNZP3Z1q4EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds==labels).item()/len(preds))\n",
        "\n",
        "class FERBase(nn.Module):\n",
        "    \n",
        "    # this takes is batch from training dl\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                     # calls the training model and generates predictions\n",
        "        loss = F.cross_entropy(out, labels)    # calculates loss compare to real labels using cross entropy\n",
        "        return loss\n",
        "    \n",
        "    # this takes in batch from validation dl\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        acc = accuracy(out, labels)            # calls the accuracy function to measure the accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "    \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()    # finds out the mean loss of the epoch batch\n",
        "        \n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()       # finds out the mean acc of the epoch batch\n",
        "        \n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzYRldNeq4ER",
        "colab_type": "text"
      },
      "source": [
        "Now we will create our model for the Facial Expression Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vlf5luvzq4ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(in_chnl, out_chnl, pool=False, padding=1):\n",
        "    layers = [\n",
        "        nn.Conv2d(in_chnl, out_chnl, kernel_size=3, padding=padding),\n",
        "        nn.BatchNorm2d(out_chnl),\n",
        "        nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class FERModel(FERBase):\n",
        "    def __init__(self, in_chnls, num_cls):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_chnls, 64, pool=True)           # 64x24x24 \n",
        "        self.conv2 = conv_block(64, 128, pool=True)                # 128x12x12\n",
        "        self.resnet1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))    # Resnet layer 1: includes 2 conv2d\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True)       # 256x6x6 \n",
        "        self.conv4 = conv_block(256, 512, pool=True)       # 512x3x3\n",
        "        self.resnet2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))    # Resnet layer 2: includes 2 conv2d\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(3),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Linear(512, num_cls))    # num_cls\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.resnet1(out) + out\n",
        "        \n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.resnet2(out) + out\n",
        "        \n",
        "        return self.classifier(out)\n",
        "        \n",
        "model = FERModel(1, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCvnD3Kuq4EW",
        "colab_type": "text"
      },
      "source": [
        "Let us nowlook if the model gives us the output array as I am hoping for. The output array must contain 7 values, that is 7 probabilities of what class could it be from the expression classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PIvHGWikq4EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, lbl in train_dl:\n",
        "    print('shape of image: ', images.shape)\n",
        "    out = model(images)\n",
        "    print('shape of output: ', out.shape)\n",
        "    print('Output: ', out[0])\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldSkE72Rq4Eb",
        "colab_type": "text"
      },
      "source": [
        "Now let us code for to utilise the GPU for the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U984Le5wq4Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QaefkFwMq4Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JiN8Zs9q4Eh",
        "colab_type": "text"
      },
      "source": [
        "Now let us wrap our datas to the available device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eMm6xRS1q4Eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm6EJAwOq4Ek",
        "colab_type": "text"
      },
      "source": [
        "## Training The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQOaX3CSq4El",
        "colab_type": "text"
      },
      "source": [
        "Since the model itself is ready, there is not any more headache left to create some functions for the training start training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1jAr589oq4El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()    # this is for stopping the model from keeping track ofold parameters\n",
        "def evaluate(model, val_loader):\n",
        "    # This function will evaluate the model and give back the val acc and loss\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "# getting the current learning rate\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "# this fit function follows the intuition of 1cycle lr\n",
        "def fit(epochs, max_lr, model, train_loader=train_dl, val_loader=val_dl, weight_decay=0, grad_clip=None, opt_func=torch.optim.Adam):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []    #keep track of the evaluation results\n",
        "    \n",
        "    # setting upcustom optimizer including weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # setting up 1cycle lr scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # training\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            \n",
        "            # gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "                \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # record the lr\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "            \n",
        "        #validation\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEC7CrYq4Eo",
        "colab_type": "text"
      },
      "source": [
        "We also need to load our model in the device too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QQSyXIOfq4Ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = to_device(FERModel(1, 7), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qkGghoAvq4Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(model, val_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4zEcRxhq4Ev",
        "colab_type": "text"
      },
      "source": [
        "Now we will train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yoJevRzbq4Ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_lr = 0.001\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "61yDhYiyq4Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "history = fit(30, max_lr, model, weight_decay=weight_decay, grad_clip=grad_clip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "g3TJfjrEq4E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "    \n",
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning rate')\n",
        "    plt.title('Learning Rate vs. Batch no.');\n",
        "    \n",
        "plot_losses(history)\n",
        "plt.figure()\n",
        "plot_lrs(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPcsEXioq4E4",
        "colab_type": "text"
      },
      "source": [
        "**History log**\n",
        "\n",
        "* model1: 1>16>32>64>128>256>256 cnn then, 256*6*6>1024>512>7 fnn, 10epoch 0.001lr, 3epoch 0.0001lr, 55%, overfit\n",
        "\n",
        "* model2: 1>64>128>256>512>1024 cnn then 1024*6*6>1024>512>128>7 fnn, 10epoch, 0.0001lr, 56%, minimum overfitting\n",
        "\n",
        "* model3: 1>128>256>600>1200>2048>1024 cnn then 1024*3*3>1024>512>7 fnn, 5epochs 1e-4lr, 6epochs 1e-5lr,5epochs, 1e-6lr, 58%, minimum overfit \n",
        "\n",
        "* resnet9: maxlr 0.001, epochs 20-30, 69%, minimum overfit\n",
        "\n",
        "* resnet9: maxlr 0.01, epoch 20, 71%\n",
        "\n",
        "* resnet9: maxlr 0.001, 30 epcohs, 72%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "UvcBom7jq4E5",
        "colab_type": "text"
      },
      "source": [
        "## Saving the Model\n",
        "\n",
        "Now since the training is done we can succesfully save our model so that we can use it in our facial recognition script!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MclojHSZq4E5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'FER2013-Resnet9.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TSFiOa8Mq4E8",
        "colab_type": "code",
        "colab": {},
        "outputId": "6e6c43bb-e13c-409e-f86a-3c5f37c805ef"
      },
      "source": [
        "!pip install jovian\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jovian\n",
            "  Downloading jovian-0.2.16-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 974 kB/s eta 0:00:011\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from jovian) (5.3.1)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from jovian) (2.23.0)\n",
            "Collecting uuid\n",
            "  Downloading uuid-1.30.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from jovian) (7.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->jovian) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->jovian) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->jovian) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->jovian) (2.9)\n",
            "Building wheels for collected packages: uuid\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6500 sha256=0c8a31fba756eebe257a64b96ddef72ac30835a04f8e26d9783db39976d2d0e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/ea/87/dd57f1ecb4f0752f3e1dbf958ebf8b36d920d190425bcdc24d\n",
            "Successfully built uuid\n",
            "Installing collected packages: uuid, jovian\n",
            "Successfully installed jovian-0.2.16 uuid-1.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qKbBTbPEq4FE",
        "colab_type": "code",
        "colab": {},
        "outputId": "e9248b07-39a0-4b4d-8d0f-d85220ee24a5"
      },
      "source": [
        "import jovian\n",
        "jovian.commit(project='facial-expression-recognizer')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Detected Kaggle notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ml/ ):\u001b[0m\n",
            "API KEY: ········\n",
            "[jovian] Uploading notebook to https://jovian.ml/jaisal1311/facial-expression-recognizer\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    require([\"base/js/namespace\"],function(Jupyter) {\n",
              "        var nbJson = JSON.stringify(Jupyter.notebook.toJSON());\n",
              "\n",
              "        console.log(\"[jovian] Extracted notebook JSON:\");\n",
              "        console.log(nbJson);\n",
              "\n",
              "        function jvnLog (data) {\n",
              "          console.log(\"Result from jovian.commit:\");\n",
              "          if (data.content.text) {\n",
              "              var result = JSON.parse(data.content.text.trim());\n",
              "              var msg = result['msg'];\n",
              "              var err = result['err'];\n",
              "              if (msg) {\n",
              "                  element.text(\"Committed successfully: \" + msg)\n",
              "              } else {\n",
              "                  alert(\"Notebook commit failed. Error: \" + (err || \"Unknown\"))\n",
              "              }\n",
              "          }\n",
              "          \n",
              "        };\n",
              "        \n",
              "        var pythonCode = `\n",
              "from contextlib import redirect_stdout, redirect_stderr\n",
              "from io import StringIO\n",
              "import json\n",
              " \n",
              "with open(\"facial-expression-recognizer.ipynb\", 'w') as f:\n",
              "    f.write(r\"\"\"${nbJson}\"\"\")\n",
              "\n",
              "jvn_update = StringIO()\n",
              "jvn_update_err = StringIO()\n",
              "with redirect_stdout(jvn_update), redirect_stderr(jvn_update_err):\n",
              "    from jovian import commit\n",
              "\n",
              "jvn_f_out = StringIO()\n",
              "jvn_f_err = StringIO()\n",
              "with redirect_stdout(jvn_f_out), redirect_stderr(jvn_f_err):\n",
              "    jvn_msg = jovian.commit(message=None, files=[], outputs=[], environment='auto', privacy='auto', filename='facial-expression-recognizer.ipynb', project='facial-expression-recognizer', new_project=None)\n",
              "\n",
              "print(json.dumps({'msg': jvn_msg, 'err': jvn_f_err.getvalue(), 'update': jvn_update.getvalue()}))\n",
              "        `;\n",
              "\n",
              "        console.log(\"Invoking jovian.commit\")\n",
              "        // console.log(pythonCode)\n",
              "\n",
              "        Jupyter.notebook.kernel.execute(pythonCode, { iopub: { output: jvnLog }});\n",
              "    });"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "e_hdJg2dq4FH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}